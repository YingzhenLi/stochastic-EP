\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{bm, subfigure}
\usepackage{inputenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{amsthm}
\usepackage{algorithm, algorithmic}
\usepackage{graphicx}
\usepackage[backgroundcolor=white,linecolor=red,bordercolor=white,textsize=tiny,textwidth=10mm]{todonotes}

\newcommand{\ica}{\hspace{0.25cm}}
\renewcommand{\arraystretch}{0.94}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}


%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09


\newtheorem{theorem}{Theorem}
\mathchardef\mhyphen="2D

\title{Stochastic Expectation Propagation}


\author{
Yingzhen Li \\
Department of Engineering\\
University of Cambridge\\
Cambridge, CB2 1PZ, UK \\
\texttt{yl494@cam.ac.uk} \\
\And
Miguel to enter details\\
\And
Richard E.~Turner \\
Affiliation \\
Address \\
\texttt{ret26@cam.ac.uk} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Expectation propagation (EP) is a deterministic approximation algorithm that is often used to perform approximate Bayesian parameter learning. EP approximates the full intractable posterior distribution through a set of local-approximations that are iteratively refined for each datapoint. EP can offer analytic and computational advantages over other approximations, such as Variational Inference (VI), and is the method of choice for a number of models \cite{can we have citations}. The local nature of EP appears to make it an ideal candidate for performing Bayesian learning on large-scale datasets. However, EP has a crucial limitation in this context: the number approximating factors need to increase with the number of data-points, $N$, which entails a large computational burden. This paper presents an extension to EP, called stochastic expectation propagation (SEP), that maintains a global posterior approximation (like VI) but updates it in a local way (like EP). SEP has the same relationship to EP as stochastic VI has to VI. Experiments on a number of synthetic and real-world data indicate that SEP performs almost as well as full EP, but reduces the memory consumption by a factor of $N$. 
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% INTRODUCTION
\input{intro}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% SECTION 2: EP, ADF & SEP %%%%%%%%%%%%
\input{section2}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% SECTION 3: THEORECTICAL UNDERSTANDINGS %
\input{section3-new}
%\input{section3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% SECTION 4: COMPUTATIONAL COMPLEXITY %%%%%
%\input{section4}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% SECTION 5: EXPERIMENTS %%%%%%%%%%%%%%%%%
\section{Experiments}
%%%%%%%%%%%% SYNTHETIC %%%%%%%%%%%%
\input{experiment_synthetic}

%%%%%%%%%%%% PBP %%%%%%%%%%%
\input{experiment_pbp}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% SECTION 6: CONCLUTIONS %%%%%%%%%%%%%%
\input{conclusions}

\subsubsection*{References}
\renewcommand{\section}[2]{}
\bibliographystyle{unsrt}
\bibliography{nips_sep}


\end{document}
