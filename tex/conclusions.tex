\section{Conclusions and future work}
This paper has presented the stochastic expectation propagation method for reducing EP's large memory consumption which is often prohibitive for large datasets. We have connected the new algorithm to a number of existing methods including assumed density filtering, variational message passing, variational inference, stochastic variational inference and averaged EP.
%
Experiments on Bayesian logistic regression (both synthetic and real world) and mixture of Gaussians clustering indicated that the new method had an accuracy that was competitive with EP.  Experiments on the probabilistic back-propagation on large real world regression datasets again showed that SEP comparably to EP with a vastly reduced memory footprint. 
%
Future experimental work will focus on developing data-partitioning methods to leverage finer-grained approximations (DESP) that showed promising experimental performance and also mini-batch updates. There is also a need for further theoretical understanding of both the new algorithms and EP itself as well as systematic empirical comparisons of EP-like algorithms and variational methods to guide the practitioners when they select an approximation scheme.
